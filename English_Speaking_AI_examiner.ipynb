{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain and LLM dolly"
      ],
      "metadata": {
        "id": "dIB1FJGALWVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain"
      ],
      "metadata": {
        "id": "rZjaGV72_wNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install \"transformers[torch]\""
      ],
      "metadata": {
        "id": "Mbt8ui74AEeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "# databricks/dolly-v2-3b\n",
        "# databricks/dolly-v2-7b\n",
        "# databricks/dolly-v2-2-8b\n",
        "# databricks/dolly-v2-12b\n",
        "\n",
        "# OpenAssistant/falcon-7b-sft-mix-2000\n",
        "# OpenAssistant/falcon-40b-sft-mix-1226\n",
        "\n",
        "\n",
        "generate_text = pipeline(model=\"databricks/dolly-v2-3b\",\n",
        "                         torch_dtype=torch.bfloat16,\n",
        "                         trust_remote_code=True,\n",
        "                         device_map=\"auto\",\n",
        "                         return_full_text=True)"
      ],
      "metadata": {
        "id": "IzeaknCwAIuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.llms import HuggingFacePipeline"
      ],
      "metadata": {
        "id": "zknNSN22AM99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Whisper for speaking-to-text trasncript"
      ],
      "metadata": {
        "id": "sYKqSgkuAsSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest commit from Github whisper repository\n",
        "! pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "id": "u9N9yfQZA0Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing command-line tool ffmpeg\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "id": "vn8AnWuMA0Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Web UI Toolkit"
      ],
      "metadata": {
        "id": "TbaqFY6ffcg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install gradio -q"
      ],
      "metadata": {
        "id": "Gh0-aXM2_xd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The App"
      ],
      "metadata": {
        "id": "BTJ36HVnkMjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "WrWXVn8-CyHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_pipeline = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "English_review_template = \"\"\"You are a professional examiner who assesses the English language proficiency of candidates taking an English test.\n",
        "You asked this question: {question} \\\n",
        "The answer was: {text}.\n",
        "\n",
        "Evaluate the answer based on the following criteria:\\\n",
        "\n",
        "- Coherence: Assess how well the candidate's answer is connected to the question.\n",
        "- Word Choice: Assess if the candidate uses appropriate words and phrases to communicate.\n",
        "- Vocabulary Range: Assess if the candidate uses a variety of vocabulary.\n",
        "- Sentence Structure: Assess the candidate's ability to use a variety of sentence structures appropriately.\n",
        "- Grammatical Accuracy: Explain how well did the candidate formed grammatically correct sentences?\n",
        "- Grammatical Errors: List and explain each grammar error in the candidate's answer.\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = PromptTemplate.from_template(English_review_template)\n",
        "\n",
        "llm_chain = LLMChain(llm=hf_pipeline, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "eSwrq56kOidq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def English_feedback(Question, audio):\n",
        "  model = whisper.load_model(\"base\")\n",
        "  text = model.transcribe(audio)\n",
        "  response = llm_chain.run({'text': text, 'question': Question})\n",
        "  return text[\"text\"], response"
      ],
      "metadata": {
        "id": "TlbWowbE_yJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(\n",
        "    title = 'English Speaking AI-examiner ',\n",
        "    fn=English_feedback,\n",
        "    inputs=[\"text\", gr.inputs.Audio(source=\"microphone\", type=\"filepath\")],\n",
        "    outputs=[ \"textbox\", \"textbox\"])\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "9h5X63sW7jSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4RHxuKWbCzz3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}